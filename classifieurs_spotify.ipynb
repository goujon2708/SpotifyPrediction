{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- SCHERRER Arthur\n",
    "- CHIRON Yoann\n",
    "- BOQUAIN Mathis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifieurs - Spotify Best Songs from 2000 to 2023\n",
    "-> Prédiction du genre des musiques populaires de 2000 à 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import des différentes librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chargement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"spotify_songs.csv\", sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Affichage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>artist</th>\n",
       "      <th>top genre</th>\n",
       "      <th>year</th>\n",
       "      <th>bpm</th>\n",
       "      <th>energy</th>\n",
       "      <th>danceability</th>\n",
       "      <th>valence</th>\n",
       "      <th>duration</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>speechiness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Flowers</td>\n",
       "      <td>Miley Cyrus</td>\n",
       "      <td>pop</td>\n",
       "      <td>2023</td>\n",
       "      <td>118</td>\n",
       "      <td>68</td>\n",
       "      <td>71</td>\n",
       "      <td>65</td>\n",
       "      <td>200</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cupid - Twin Ver.</td>\n",
       "      <td>FIFTY FIFTY</td>\n",
       "      <td>k-pop girl group</td>\n",
       "      <td>2023</td>\n",
       "      <td>120</td>\n",
       "      <td>59</td>\n",
       "      <td>78</td>\n",
       "      <td>73</td>\n",
       "      <td>174</td>\n",
       "      <td>44</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BESO</td>\n",
       "      <td>ROSALÍA</td>\n",
       "      <td>pop</td>\n",
       "      <td>2023</td>\n",
       "      <td>95</td>\n",
       "      <td>64</td>\n",
       "      <td>77</td>\n",
       "      <td>53</td>\n",
       "      <td>195</td>\n",
       "      <td>74</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Boy's a liar Pt. 2</td>\n",
       "      <td>PinkPantheress</td>\n",
       "      <td>bronx drill</td>\n",
       "      <td>2023</td>\n",
       "      <td>133</td>\n",
       "      <td>81</td>\n",
       "      <td>70</td>\n",
       "      <td>86</td>\n",
       "      <td>131</td>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Creepin' (with The Weeknd &amp; 21 Savage)</td>\n",
       "      <td>Metro Boomin</td>\n",
       "      <td>rap</td>\n",
       "      <td>2022</td>\n",
       "      <td>98</td>\n",
       "      <td>62</td>\n",
       "      <td>72</td>\n",
       "      <td>17</td>\n",
       "      <td>222</td>\n",
       "      <td>42</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    title          artist         top genre  \\\n",
       "0                                 Flowers     Miley Cyrus               pop   \n",
       "1                       Cupid - Twin Ver.     FIFTY FIFTY  k-pop girl group   \n",
       "2                                    BESO         ROSALÍA               pop   \n",
       "3                      Boy's a liar Pt. 2  PinkPantheress       bronx drill   \n",
       "4  Creepin' (with The Weeknd & 21 Savage)    Metro Boomin               rap   \n",
       "\n",
       "   year  bpm  energy  danceability  valence  duration  acousticness  \\\n",
       "0  2023  118      68            71       65       200             6   \n",
       "1  2023  120      59            78       73       174            44   \n",
       "2  2023   95      64            77       53       195            74   \n",
       "3  2023  133      81            70       86       131            25   \n",
       "4  2022   98      62            72       17       222            42   \n",
       "\n",
       "   speechiness  \n",
       "0            7  \n",
       "1            3  \n",
       "2           14  \n",
       "3            5  \n",
       "4            5  "
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discrétisation des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Certaines features ont été supprimées où ne sont pas utilisées car peu de pertinences face au sujet étudié :\n",
    "- dB\n",
    "- liveness\n",
    "- popularity : tous les morceaux sont populaires"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature à discrétiser\n",
    "\n",
    "- genre\n",
    "- bpm\n",
    "- danceability\n",
    "- energy\n",
    "- valence\n",
    "- acousticness\n",
    "- speechiness\n",
    "- year \n",
    "- duration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discrétisation du genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>artist</th>\n",
       "      <th>top genre</th>\n",
       "      <th>year</th>\n",
       "      <th>bpm</th>\n",
       "      <th>energy</th>\n",
       "      <th>danceability</th>\n",
       "      <th>valence</th>\n",
       "      <th>duration</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>speechiness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Flowers</td>\n",
       "      <td>Miley Cyrus</td>\n",
       "      <td>pop</td>\n",
       "      <td>2023</td>\n",
       "      <td>118</td>\n",
       "      <td>68</td>\n",
       "      <td>71</td>\n",
       "      <td>65</td>\n",
       "      <td>200</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cupid - Twin Ver.</td>\n",
       "      <td>FIFTY FIFTY</td>\n",
       "      <td>pop</td>\n",
       "      <td>2023</td>\n",
       "      <td>120</td>\n",
       "      <td>59</td>\n",
       "      <td>78</td>\n",
       "      <td>73</td>\n",
       "      <td>174</td>\n",
       "      <td>44</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BESO</td>\n",
       "      <td>ROSALÍA</td>\n",
       "      <td>pop</td>\n",
       "      <td>2023</td>\n",
       "      <td>95</td>\n",
       "      <td>64</td>\n",
       "      <td>77</td>\n",
       "      <td>53</td>\n",
       "      <td>195</td>\n",
       "      <td>74</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Creepin' (with The Weeknd &amp; 21 Savage)</td>\n",
       "      <td>Metro Boomin</td>\n",
       "      <td>rap</td>\n",
       "      <td>2022</td>\n",
       "      <td>98</td>\n",
       "      <td>62</td>\n",
       "      <td>72</td>\n",
       "      <td>17</td>\n",
       "      <td>222</td>\n",
       "      <td>42</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Anti-Hero</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>pop</td>\n",
       "      <td>2022</td>\n",
       "      <td>97</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>53</td>\n",
       "      <td>201</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    title        artist top genre  year  bpm  \\\n",
       "0                                 Flowers   Miley Cyrus       pop  2023  118   \n",
       "1                       Cupid - Twin Ver.   FIFTY FIFTY       pop  2023  120   \n",
       "2                                    BESO       ROSALÍA       pop  2023   95   \n",
       "4  Creepin' (with The Weeknd & 21 Savage)  Metro Boomin       rap  2022   98   \n",
       "8                               Anti-Hero  Taylor Swift       pop  2022   97   \n",
       "\n",
       "   energy  danceability  valence  duration  acousticness  speechiness  \n",
       "0      68            71       65       200             6            7  \n",
       "1      59            78       73       174            44            3  \n",
       "2      64            77       53       195            74           14  \n",
       "4      62            72       17       222            42            5  \n",
       "8      64            64       53       201            13            5  "
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sorted = df.sort_values(by=\"top genre\")\n",
    "\n",
    "df['top genre'] = df['top genre'].str.replace('.*pop.*', 'pop', regex=True)\n",
    "df['top genre'] = df['top genre'].str.replace('.*hip hop.*', 'rap', regex=True)\n",
    "df['top genre'] = df['top genre'].str.replace('.*hip-hop.*', 'rap', regex=True)\n",
    "df['top genre'] = df['top genre'].str.replace('.*rap.*', 'rap', regex=True)\n",
    "df['top genre'] = df['top genre'].str.replace('.*metal.*', 'metal', regex=True)\n",
    "df['top genre'] = df['top genre'].str.replace('.*r&b.*', 'r&b', regex=True)\n",
    "df['top genre'] = df['top genre'].str.replace('.*edm.*', 'techno', regex=True)\n",
    "df['top genre'] = df['top genre'].str.replace('.*electro.*', 'techno', regex=True)\n",
    "df['top genre'] = df['top genre'].str.replace('.*electro dance music.*', 'techno', regex=True)\n",
    "df['top genre'] = df['top genre'].str.replace('.*indie.*', 'indian', regex=True)\n",
    "df['top genre'] = df['top genre'].str.replace('.*rock.*', 'rock', regex=True)\n",
    "df['top genre'] = df['top genre'].str.replace('.*house.*', 'techno', regex=True)\n",
    "df['top genre'] = df['top genre'].str.replace('.*jazz.*', 'jazz', regex=True)\n",
    "df['top genre'] = df['top genre'].str.replace('.*mellow.*', 'rock', regex=True)\n",
    "df['top genre'] = df['top genre'].str.replace('.*soul.*', 'soul', regex=True)\n",
    "\n",
    "genres_to_keep = ['pop', 'rap', 'metal', 'r&b', 'techno', 'rock']\n",
    "mask = df['top genre'].isin(genres_to_keep)\n",
    "df = df[mask]\n",
    "\n",
    "df_count = df['top genre'].value_counts()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Méthode de discrétisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>artist</th>\n",
       "      <th>top genre</th>\n",
       "      <th>year</th>\n",
       "      <th>bpm</th>\n",
       "      <th>energy</th>\n",
       "      <th>danceability</th>\n",
       "      <th>valence</th>\n",
       "      <th>duration</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>speechiness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Flowers</td>\n",
       "      <td>Miley Cyrus</td>\n",
       "      <td>pop</td>\n",
       "      <td>2020's</td>\n",
       "      <td>Medium bpm</td>\n",
       "      <td>Moderate Energy</td>\n",
       "      <td>High Danceability</td>\n",
       "      <td>neutral</td>\n",
       "      <td>short</td>\n",
       "      <td>Moderate Acousticness</td>\n",
       "      <td>High Speechiness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cupid - Twin Ver.</td>\n",
       "      <td>FIFTY FIFTY</td>\n",
       "      <td>pop</td>\n",
       "      <td>2020's</td>\n",
       "      <td>Medium bpm</td>\n",
       "      <td>Low Energy</td>\n",
       "      <td>Very High Danceability</td>\n",
       "      <td>positive</td>\n",
       "      <td>short</td>\n",
       "      <td>Very High Acousticness</td>\n",
       "      <td>Low Speechiness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BESO</td>\n",
       "      <td>ROSALÍA</td>\n",
       "      <td>pop</td>\n",
       "      <td>2020's</td>\n",
       "      <td>Low bpm</td>\n",
       "      <td>Moderate Energy</td>\n",
       "      <td>High Danceability</td>\n",
       "      <td>neutral</td>\n",
       "      <td>short</td>\n",
       "      <td>Very High Acousticness</td>\n",
       "      <td>Very High Speechiness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Creepin' (with The Weeknd &amp; 21 Savage)</td>\n",
       "      <td>Metro Boomin</td>\n",
       "      <td>rap</td>\n",
       "      <td>2020's</td>\n",
       "      <td>Low bpm</td>\n",
       "      <td>Moderate Energy</td>\n",
       "      <td>High Danceability</td>\n",
       "      <td>negative</td>\n",
       "      <td>medium</td>\n",
       "      <td>Very High Acousticness</td>\n",
       "      <td>Moderate Speechiness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Anti-Hero</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>pop</td>\n",
       "      <td>2020's</td>\n",
       "      <td>Low bpm</td>\n",
       "      <td>Moderate Energy</td>\n",
       "      <td>Moderate Danceability</td>\n",
       "      <td>neutral</td>\n",
       "      <td>short</td>\n",
       "      <td>High Acousticness</td>\n",
       "      <td>Moderate Speechiness</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    title        artist top genre    year  \\\n",
       "0                                 Flowers   Miley Cyrus       pop  2020's   \n",
       "1                       Cupid - Twin Ver.   FIFTY FIFTY       pop  2020's   \n",
       "2                                    BESO       ROSALÍA       pop  2020's   \n",
       "4  Creepin' (with The Weeknd & 21 Savage)  Metro Boomin       rap  2020's   \n",
       "8                               Anti-Hero  Taylor Swift       pop  2020's   \n",
       "\n",
       "          bpm           energy            danceability   valence duration  \\\n",
       "0  Medium bpm  Moderate Energy       High Danceability   neutral    short   \n",
       "1  Medium bpm       Low Energy  Very High Danceability  positive    short   \n",
       "2     Low bpm  Moderate Energy       High Danceability   neutral    short   \n",
       "4     Low bpm  Moderate Energy       High Danceability  negative   medium   \n",
       "8     Low bpm  Moderate Energy   Moderate Danceability   neutral    short   \n",
       "\n",
       "             acousticness            speechiness  \n",
       "0   Moderate Acousticness       High Speechiness  \n",
       "1  Very High Acousticness        Low Speechiness  \n",
       "2  Very High Acousticness  Very High Speechiness  \n",
       "4  Very High Acousticness   Moderate Speechiness  \n",
       "8       High Acousticness   Moderate Speechiness  "
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def discretize_column(df, column_name, num_intervals, labels=None):\n",
    "    \"\"\"\n",
    "    Discrétise une colonne de données dans un DataFrame en fonction d'un nombre d'intervalles spécifié.\n",
    "\n",
    "    Args:\n",
    "    - df : DataFrame contenant les données\n",
    "    - column_name : Nom de la colonne à discrétiser\n",
    "    - num_intervals : Nombre d'intervalles souhaité\n",
    "    - labels : Liste des labels pour les catégories discrétisées\n",
    "\n",
    "    Returns:\n",
    "    - Un DataFrame avec la colonne initiale remplacée par les données discrétisées\n",
    "    \"\"\"\n",
    "\n",
    "    # Calcul des quantiles en fonction du nombre d'intervalles\n",
    "    quantiles = [i / num_intervals for i in range(num_intervals)]\n",
    "\n",
    "    # Calcul des valeurs des quantiles\n",
    "    quantiles_values = df[column_name].quantile(quantiles)\n",
    "\n",
    "    # Définition des intervalles\n",
    "    intervals = [df[column_name].min()] + list(quantiles_values.unique()) + [df[column_name].max()]\n",
    "\n",
    "    # Définition des labels si spécifiés, sinon utiliser les intervalles comme labels\n",
    "    if labels is None:\n",
    "        labels = [f\"Interval {i+1}\" for i in range(len(quantiles) + 1)]\n",
    "\n",
    "    # Discrétisation de la colonne en supprimant les bords d'intervalles en double\n",
    "    df[column_name] = pd.cut(df[column_name], bins=intervals, labels=labels, include_lowest=True, duplicates='drop')\n",
    "\n",
    "    return df\n",
    "\n",
    "df = discretize_column(df, 'bpm', num_intervals=4, labels=['Low bpm', 'Medium bpm', 'High bpm', 'Very High bpm'])\n",
    "df = discretize_column(df, 'danceability', num_intervals=4, labels=['Low Danceability', 'Moderate Danceability', 'High Danceability', 'Very High Danceability'])\n",
    "df = discretize_column(df, 'energy', num_intervals=4, labels=['Low Energy', 'Moderate Energy', 'High Energy', 'Very High Energy'])\n",
    "df = discretize_column(df, 'valence', num_intervals=3, labels=['negative', 'neutral', 'positive'])\n",
    "df = discretize_column(df, 'acousticness', num_intervals=4, labels= ['Low Acousticness', 'Moderate Acousticness', 'High Acousticness', 'Very High Acousticness'])\n",
    "df = discretize_column(df, 'speechiness', num_intervals=4, labels=['Low Speechiness', 'Moderate Speechiness', 'High Speechiness', 'Very High Speechiness'])\n",
    "df = discretize_column(df, 'year', num_intervals=3, labels=[\"2000's\",\"2010's\", \"2020's\"])\n",
    "df = discretize_column(df, 'duration', num_intervals=3, labels=['short', 'medium', 'long'])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Séparation du dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Categorical' with dtype category does not support reduction 'mean'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\yoann\\OneDrive\\Bureau\\M1\\Methodes_classiques _IA\\SpotifyPrediction\\classifieurs_spotify.ipynb Cellule 17\u001b[0m line \u001b[0;36m6\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/yoann/OneDrive/Bureau/M1/Methodes_classiques%20_IA/SpotifyPrediction/classifieurs_spotify.ipynb#X22sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m y \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39m\u001b[39mtop genre\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/yoann/OneDrive/Bureau/M1/Methodes_classiques%20_IA/SpotifyPrediction/classifieurs_spotify.ipynb#X22sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m x_train, x_test, y_train, y_test \u001b[39m=\u001b[39m train_test_split(x, y, test_size \u001b[39m=\u001b[39m \u001b[39m0.2\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m101\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/yoann/OneDrive/Bureau/M1/Methodes_classiques%20_IA/SpotifyPrediction/classifieurs_spotify.ipynb#X22sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m means_train \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mmean(x_train, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/yoann/OneDrive/Bureau/M1/Methodes_classiques%20_IA/SpotifyPrediction/classifieurs_spotify.ipynb#X22sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m stds_train \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mstd(x_train, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/yoann/OneDrive/Bureau/M1/Methodes_classiques%20_IA/SpotifyPrediction/classifieurs_spotify.ipynb#X22sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m# Étape 2 : Application de la standardisation\u001b[39;00m\n",
      "File \u001b[1;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mmean\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\yoann\\anaconda3\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:3462\u001b[0m, in \u001b[0;36mmean\u001b[1;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[0;32m   3460\u001b[0m         \u001b[39mpass\u001b[39;00m\n\u001b[0;32m   3461\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 3462\u001b[0m         \u001b[39mreturn\u001b[39;00m mean(axis\u001b[39m=\u001b[39maxis, dtype\u001b[39m=\u001b[39mdtype, out\u001b[39m=\u001b[39mout, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   3464\u001b[0m \u001b[39mreturn\u001b[39;00m _methods\u001b[39m.\u001b[39m_mean(a, axis\u001b[39m=\u001b[39maxis, dtype\u001b[39m=\u001b[39mdtype,\n\u001b[0;32m   3465\u001b[0m                       out\u001b[39m=\u001b[39mout, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\yoann\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:11338\u001b[0m, in \u001b[0;36mDataFrame.mean\u001b[1;34m(self, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[0;32m  11330\u001b[0m \u001b[39m@doc\u001b[39m(make_doc(\u001b[39m\"\u001b[39m\u001b[39mmean\u001b[39m\u001b[39m\"\u001b[39m, ndim\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m))\n\u001b[0;32m  11331\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmean\u001b[39m(\n\u001b[0;32m  11332\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  11336\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m  11337\u001b[0m ):\n\u001b[1;32m> 11338\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mmean(axis, skipna, numeric_only, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m  11339\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(result, Series):\n\u001b[0;32m  11340\u001b[0m         result \u001b[39m=\u001b[39m result\u001b[39m.\u001b[39m__finalize__(\u001b[39mself\u001b[39m, method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmean\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\yoann\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:11978\u001b[0m, in \u001b[0;36mNDFrame.mean\u001b[1;34m(self, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[0;32m  11971\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmean\u001b[39m(\n\u001b[0;32m  11972\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m  11973\u001b[0m     axis: Axis \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  11976\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m  11977\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Series \u001b[39m|\u001b[39m \u001b[39mfloat\u001b[39m:\n\u001b[1;32m> 11978\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stat_function(\n\u001b[0;32m  11979\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mmean\u001b[39m\u001b[39m\"\u001b[39m, nanops\u001b[39m.\u001b[39mnanmean, axis, skipna, numeric_only, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[0;32m  11980\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\yoann\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:11935\u001b[0m, in \u001b[0;36mNDFrame._stat_function\u001b[1;34m(self, name, func, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[0;32m  11931\u001b[0m nv\u001b[39m.\u001b[39mvalidate_func(name, (), kwargs)\n\u001b[0;32m  11933\u001b[0m validate_bool_kwarg(skipna, \u001b[39m\"\u001b[39m\u001b[39mskipna\u001b[39m\u001b[39m\"\u001b[39m, none_allowed\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m> 11935\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reduce(\n\u001b[0;32m  11936\u001b[0m     func, name\u001b[39m=\u001b[39mname, axis\u001b[39m=\u001b[39maxis, skipna\u001b[39m=\u001b[39mskipna, numeric_only\u001b[39m=\u001b[39mnumeric_only\n\u001b[0;32m  11937\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\yoann\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:11207\u001b[0m, in \u001b[0;36mDataFrame._reduce\u001b[1;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[0m\n\u001b[0;32m  11203\u001b[0m     df \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mT\n\u001b[0;32m  11205\u001b[0m \u001b[39m# After possibly _get_data and transposing, we are now in the\u001b[39;00m\n\u001b[0;32m  11206\u001b[0m \u001b[39m#  simple case where we can use BlockManager.reduce\u001b[39;00m\n\u001b[1;32m> 11207\u001b[0m res \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39m_mgr\u001b[39m.\u001b[39mreduce(blk_func)\n\u001b[0;32m  11208\u001b[0m out \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39m_constructor_from_mgr(res, axes\u001b[39m=\u001b[39mres\u001b[39m.\u001b[39maxes)\u001b[39m.\u001b[39miloc[\u001b[39m0\u001b[39m]\n\u001b[0;32m  11209\u001b[0m \u001b[39mif\u001b[39;00m out_dtype \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m out\u001b[39m.\u001b[39mdtype \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mboolean\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\yoann\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:1459\u001b[0m, in \u001b[0;36mBlockManager.reduce\u001b[1;34m(self, func)\u001b[0m\n\u001b[0;32m   1457\u001b[0m res_blocks: \u001b[39mlist\u001b[39m[Block] \u001b[39m=\u001b[39m []\n\u001b[0;32m   1458\u001b[0m \u001b[39mfor\u001b[39;00m blk \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mblocks:\n\u001b[1;32m-> 1459\u001b[0m     nbs \u001b[39m=\u001b[39m blk\u001b[39m.\u001b[39mreduce(func)\n\u001b[0;32m   1460\u001b[0m     res_blocks\u001b[39m.\u001b[39mextend(nbs)\n\u001b[0;32m   1462\u001b[0m index \u001b[39m=\u001b[39m Index([\u001b[39mNone\u001b[39;00m])  \u001b[39m# placeholder\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\yoann\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py:377\u001b[0m, in \u001b[0;36mBlock.reduce\u001b[1;34m(self, func)\u001b[0m\n\u001b[0;32m    371\u001b[0m \u001b[39m@final\u001b[39m\n\u001b[0;32m    372\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mreduce\u001b[39m(\u001b[39mself\u001b[39m, func) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mlist\u001b[39m[Block]:\n\u001b[0;32m    373\u001b[0m     \u001b[39m# We will apply the function and reshape the result into a single-row\u001b[39;00m\n\u001b[0;32m    374\u001b[0m     \u001b[39m#  Block with the same mgr_locs; squeezing will be done at a higher level\u001b[39;00m\n\u001b[0;32m    375\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m\n\u001b[1;32m--> 377\u001b[0m     result \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalues)\n\u001b[0;32m    379\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalues\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    380\u001b[0m         res_values \u001b[39m=\u001b[39m result\n",
      "File \u001b[1;32mc:\\Users\\yoann\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:11128\u001b[0m, in \u001b[0;36mDataFrame._reduce.<locals>.blk_func\u001b[1;34m(values, axis)\u001b[0m\n\u001b[0;32m  11126\u001b[0m     dtype_has_keepdims[values\u001b[39m.\u001b[39mdtype] \u001b[39m=\u001b[39m has_keepdims\n\u001b[0;32m  11127\u001b[0m \u001b[39mif\u001b[39;00m has_keepdims:\n\u001b[1;32m> 11128\u001b[0m     \u001b[39mreturn\u001b[39;00m values\u001b[39m.\u001b[39m_reduce(name, skipna\u001b[39m=\u001b[39mskipna, keepdims\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m  11129\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m  11130\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m  11131\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(values)\u001b[39m}\u001b[39;00m\u001b[39m._reduce will require a `keepdims` parameter \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m  11132\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39min the future\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m  11133\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m  11134\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[0;32m  11135\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\yoann\\anaconda3\\Lib\\site-packages\\pandas\\core\\arrays\\categorical.py:2325\u001b[0m, in \u001b[0;36mCategorical._reduce\u001b[1;34m(self, name, skipna, keepdims, **kwargs)\u001b[0m\n\u001b[0;32m   2322\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_reduce\u001b[39m(\n\u001b[0;32m   2323\u001b[0m     \u001b[39mself\u001b[39m, name: \u001b[39mstr\u001b[39m, \u001b[39m*\u001b[39m, skipna: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m, keepdims: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[0;32m   2324\u001b[0m ):\n\u001b[1;32m-> 2325\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m_reduce(name, skipna\u001b[39m=\u001b[39mskipna, keepdims\u001b[39m=\u001b[39mkeepdims, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   2326\u001b[0m     \u001b[39mif\u001b[39;00m name \u001b[39min\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39margmax\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39margmin\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[0;32m   2327\u001b[0m         \u001b[39m# don't wrap in Categorical!\u001b[39;00m\n\u001b[0;32m   2328\u001b[0m         \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\yoann\\anaconda3\\Lib\\site-packages\\pandas\\core\\arrays\\base.py:1857\u001b[0m, in \u001b[0;36mExtensionArray._reduce\u001b[1;34m(self, name, skipna, keepdims, **kwargs)\u001b[0m\n\u001b[0;32m   1855\u001b[0m meth \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, name, \u001b[39mNone\u001b[39;00m)\n\u001b[0;32m   1856\u001b[0m \u001b[39mif\u001b[39;00m meth \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1857\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[0;32m   1858\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m with dtype \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdtype\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1859\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mdoes not support reduction \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1860\u001b[0m     )\n\u001b[0;32m   1861\u001b[0m result \u001b[39m=\u001b[39m meth(skipna\u001b[39m=\u001b[39mskipna, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1862\u001b[0m \u001b[39mif\u001b[39;00m keepdims:\n",
      "\u001b[1;31mTypeError\u001b[0m: 'Categorical' with dtype category does not support reduction 'mean'"
     ]
    }
   ],
   "source": [
    "x = df[['bpm','danceability','energy','valence','acousticness','speechiness','year','duration']]\n",
    "y = df['top genre']\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state=101)\n",
    "\n",
    "means_train = np.mean(x_train, axis=0)\n",
    "stds_train = np.std(x_train, axis=0)\n",
    "\n",
    "# Étape 2 : Application de la standardisation\n",
    "train_std = (x_train - means_train) / stds_train\n",
    "\n",
    "means_test = np.mean(x_test, axis=0)\n",
    "stds_test = np.std(x_test, axis=0)\n",
    "\n",
    "# Étape 2 : Application de la standardisation\n",
    "test_std = (x_test - means_test) / stds_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervisé"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ZeroR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn_zeror(x_train, y_train):\n",
    "    unique_labels, counts = np.unique(y_train, return_counts=True)\n",
    "\n",
    "    # Trouvez l'indice de l'étiquette avec le nombre le plus élevé\n",
    "    index_max_count = np.argmax(counts)\n",
    "    \n",
    "    # L'étiquette avec le nombre le plus élevé est à l'indice index_max_count\n",
    "    most_common_label = unique_labels[index_max_count]\n",
    "    \n",
    "    return most_common_label \n",
    "\n",
    "def class_zeror(model, x_test):\n",
    "    return [model]* len(x_test)\n",
    "\n",
    "('accuracy =  54.947916666666664%',\n",
    " 'précision =  9.15798611111111%',\n",
    " 'rappel =  16.666666666666664%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OneR Mathis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('accuracy =  58.59375%',\n",
       " 'précision =  18.470211565260453%',\n",
       " 'rappel =  23.08232403019133%')"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def learn_oner(x_train_dis, y_train_dis):\n",
    "    best_feature = None\n",
    "    best_error_rate = 1.0\n",
    "    best_rules = {}\n",
    "\n",
    "    for feature in x_train_dis.columns:\n",
    "        unique_classes = y_train_dis.unique()\n",
    "        best_rule = {}\n",
    "        \n",
    "        for value in x_train_dis[feature].unique():\n",
    "            value_counts = {}\n",
    "            for class_ in unique_classes:\n",
    "                value_counts[class_] = len(y_train_dis[(x_train_dis[feature] == value) & (y_train_dis == class_)])\n",
    "\n",
    "            best_class = max(value_counts, key=value_counts.get)\n",
    "            best_rule[value] = best_class\n",
    "\n",
    "        # Calculer le taux d'erreur pour cette caractéristique\n",
    "        error_rate = 0\n",
    "        for value in x_train_dis[feature].unique():\n",
    "            error_rate += len(y_train_dis[(x_train_dis[feature] == value) & (y_train_dis != best_rule[value])])\n",
    "\n",
    "        error_rate /= len(x_train_dis)\n",
    "\n",
    "        if error_rate < best_error_rate:\n",
    "            best_error_rate = error_rate\n",
    "            best_feature = feature\n",
    "            best_rules = best_rule\n",
    "\n",
    "    return {best_feature: best_rules}\n",
    "\n",
    "def class_oner(model, x_test_dis):\n",
    "    predictions = []\n",
    "    feature = list(model.keys())[0]\n",
    "\n",
    "    for index, row in x_test_dis.iterrows():\n",
    "        feature_value = row[feature]\n",
    "        if feature_value in model[feature]:\n",
    "            predicted_class = model[feature][feature_value]\n",
    "            predictions.append(predicted_class)\n",
    "    return pd.Series(predictions)\n",
    "\n",
    "evaluate(y_test,class_oner(learn_oner(x_train, y_train),x_test))\n",
    "\n",
    "('accuracy =  58.59375%',\n",
    " 'précision =  18.470211565260453%',\n",
    " 'rappel =  23.08232403019133%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naïve Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'metal': (bpm             0.162689\n",
      "danceability   -1.032868\n",
      "energy          0.810671\n",
      "valence        -0.243530\n",
      "acousticness   -0.599639\n",
      "speechiness    -0.573655\n",
      "year           -1.117547\n",
      "duration        0.152217\n",
      "dtype: float64, bpm             1.010292\n",
      "danceability    0.541361\n",
      "energy          0.660004\n",
      "valence         0.968002\n",
      "acousticness    0.156728\n",
      "speechiness     0.091603\n",
      "year            0.433374\n",
      "duration        0.911803\n",
      "dtype: float64), 'pop': (bpm            -0.001309\n",
      "danceability    0.035184\n",
      "energy         -0.036292\n",
      "valence         0.079128\n",
      "acousticness    0.134779\n",
      "speechiness    -0.163618\n",
      "year            0.097914\n",
      "duration       -0.049201\n",
      "dtype: float64, bpm             0.923790\n",
      "danceability    0.922496\n",
      "energy          1.014045\n",
      "valence         1.062304\n",
      "acousticness    1.255534\n",
      "speechiness     0.703047\n",
      "year            0.951361\n",
      "duration        0.879905\n",
      "dtype: float64), 'r&b': (bpm            -0.289288\n",
      "danceability   -0.091960\n",
      "energy         -0.326143\n",
      "valence        -0.165616\n",
      "acousticness    0.133368\n",
      "speechiness    -0.113562\n",
      "year           -0.270045\n",
      "duration        0.206794\n",
      "dtype: float64, bpm             1.117338\n",
      "danceability    0.831548\n",
      "energy          0.794693\n",
      "valence         0.716388\n",
      "acousticness    0.763933\n",
      "speechiness     0.570481\n",
      "year            1.444630\n",
      "duration        0.547394\n",
      "dtype: float64), 'rap': (bpm            -0.031764\n",
      "danceability    0.350656\n",
      "energy         -0.158979\n",
      "valence        -0.044970\n",
      "acousticness   -0.118751\n",
      "speechiness     0.765308\n",
      "year            0.019219\n",
      "duration        0.112788\n",
      "dtype: float64, bpm             1.318578\n",
      "danceability    0.905124\n",
      "energy          0.930443\n",
      "valence         0.966095\n",
      "acousticness    0.565569\n",
      "speechiness     1.556149\n",
      "year            0.987577\n",
      "duration        1.282659\n",
      "dtype: float64), 'rock': (bpm             0.152085\n",
      "danceability   -0.837698\n",
      "energy          0.341854\n",
      "valence        -0.038698\n",
      "acousticness   -0.196397\n",
      "speechiness    -0.523856\n",
      "year           -0.373914\n",
      "duration        0.024952\n",
      "dtype: float64, bpm             1.043701\n",
      "danceability    0.931919\n",
      "energy          1.093294\n",
      "valence         0.820595\n",
      "acousticness    0.908049\n",
      "speechiness     0.162037\n",
      "year            0.715939\n",
      "duration        1.153008\n",
      "dtype: float64), 'techno': (bpm             0.111830\n",
      "danceability    0.010344\n",
      "energy          0.385669\n",
      "valence        -0.250060\n",
      "acousticness   -0.351621\n",
      "speechiness    -0.405526\n",
      "year            0.351851\n",
      "duration       -0.291684\n",
      "dtype: float64, bpm             0.190368\n",
      "danceability    0.638400\n",
      "energy          0.566676\n",
      "valence         0.912878\n",
      "acousticness    0.510950\n",
      "speechiness     0.301834\n",
      "year            0.693035\n",
      "duration        1.134877\n",
      "dtype: float64)}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('accuracy =  34.11458333333333%',\n",
       " 'précision =  33.65118265965724%',\n",
       " 'rappel =  49.11172244314914%')"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calculate_likelihood(mean, var, x):\n",
    "    eps = 1e-4  \n",
    "    coef = 1.0 / np.sqrt(2.0 * np.pi * var + eps)\n",
    "    exponent = np.exp(-((x - mean) ** 2) / (2 * (var + eps)))\n",
    "    return coef * exponent\n",
    "\n",
    "def learn_naive_bayes(X, y):\n",
    "    \n",
    "    classes = np.unique(y)  \n",
    "    mean_var_by_class = {} \n",
    "\n",
    "    for c in classes:\n",
    "        X_class = X[y == c]\n",
    "        mean = X_class.mean(axis=0)\n",
    "        var = X_class.var(axis=0)\n",
    "        mean_var_by_class[c] = (mean, var)\n",
    "\n",
    "    return mean_var_by_class\n",
    "\n",
    "def class_naive_bayes(mean_var_by_class, X):\n",
    "    predictions = []\n",
    "    for x in X:\n",
    "        class_probs = {}\n",
    "        for c, (mean, var) in mean_var_by_class.items():\n",
    "            likelihood = calculate_likelihood(mean, var, x)\n",
    "            class_probs[c] = np.prod(likelihood)\n",
    "        predicted_class = max(class_probs, key=class_probs.get)\n",
    "        predictions.append(predicted_class)\n",
    "    return predictions\n",
    "\n",
    "mean = learn_naive_bayes(train_std, y_train)\n",
    "\n",
    "naive_baisenaive_classification = class_naive_bayes(mean, np.array(test_std))\n",
    "\n",
    "print(mean)\n",
    "\n",
    "evaluate(y_test, naive_baisenaive_classification)\n",
    "\n",
    "('accuracy =  34.11458333333333%',\n",
    " 'précision =  33.65118265965724%',\n",
    " 'rappel =  49.11172244314914%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KPPV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('accuracy =  52.864583333333336%',\n",
       " 'précision =  36.47991081260207%',\n",
       " 'rappel =  33.03351582502587%')"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def euclidean_distance(array1, array2):\n",
    "    squared_diff = np.square(array1 - array2)\n",
    "    sum_squared_diff = np.sum(squared_diff)\n",
    "    return np.sqrt(sum_squared_diff)\n",
    "\n",
    "from random import choice\n",
    "\n",
    "def k_nearest_neighbors(X_train, Y_train, X_test, k=3):\n",
    "    y_pred = []\n",
    "    for x in X_test.values:\n",
    "        distances = [euclidean_distance(x, x_train) for x_train in X_train.values]\n",
    "        k_indices = np.argsort(distances)[:k]\n",
    "        k_nearest_labels = [Y_train.values[i] for i in k_indices]\n",
    "\n",
    "        label_counts = dict()\n",
    "        for label in k_nearest_labels:\n",
    "            label_counts[label] = label_counts.get(label, 0) + 1\n",
    "\n",
    "        most_common_labels = [label for label, count in label_counts.items() if count == max(label_counts.values())]\n",
    "        predicted_label = choice(most_common_labels)\n",
    "\n",
    "        y_pred.append(predicted_label)\n",
    "    return np.array(y_pred)\n",
    "\n",
    "pred = k_nearest_neighbors(train_std, y_train, test_std)\n",
    "\n",
    "evaluate(y_test, pred)\n",
    "\n",
    "('accuracy =  53.90625%',\n",
    " 'précision =  33.829944801811806%',\n",
    " 'rappel =  34.21549756980383%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non Supervisé"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-means Mathis Boquain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'new_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/poulp/Documents/GitHub/SpotifyPrediction/classifieurs_spotify.ipynb Cell 28\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/poulp/Documents/GitHub/SpotifyPrediction/classifieurs_spotify.ipynb#X46sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m k_values \u001b[39m=\u001b[39m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, \u001b[39m20\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/poulp/Documents/GitHub/SpotifyPrediction/classifieurs_spotify.ipynb#X46sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m wcss_values \u001b[39m=\u001b[39m []\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/poulp/Documents/GitHub/SpotifyPrediction/classifieurs_spotify.ipynb#X46sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m new_df\u001b[39m.\u001b[39mreset_index(drop\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, inplace\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)  \u001b[39m# Réinitialiser complètement l'index\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/poulp/Documents/GitHub/SpotifyPrediction/classifieurs_spotify.ipynb#X46sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m \u001b[39m# Réinitialiser les données après l'opération précédente\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/poulp/Documents/GitHub/SpotifyPrediction/classifieurs_spotify.ipynb#X46sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m X_music \u001b[39m=\u001b[39m new_df\u001b[39m.\u001b[39mvalues\n",
      "\u001b[0;31mNameError\u001b[0m: name 'new_df' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def initialize_centroids(X, k):\n",
    "    indices = np.random.choice(X.shape[0], k, replace=False)\n",
    "    centroids = X[indices]\n",
    "    return centroids\n",
    "\n",
    "# Fonction pour attribuer chaque point au centroïde le plus proche\n",
    "def assign_to_nearest(X, centroids):\n",
    "    clusters = np.zeros(X.shape[0])\n",
    "    for i in range(X.shape[0]):\n",
    "        distances = np.linalg.norm(X[i] - centroids, axis=1)\n",
    "        clusters[i] = np.argmin(distances)\n",
    "    return clusters\n",
    "\n",
    "# Fonction pour mettre à jour les centroides\n",
    "def update_centroids(X, clusters, k):\n",
    "    centroids = np.zeros((k, X.shape[1]))\n",
    "    for i in range(k):\n",
    "        cluster_points = X[clusters == i]\n",
    "        centroids[i] = np.mean(cluster_points, axis=0)\n",
    "    return centroids\n",
    "\n",
    "# Fonction d'algorithme de k-moyennes\n",
    "def k_means(X, k, max_iterations=100):\n",
    "    centroids = initialize_centroids(X, k)\n",
    "    for _ in range(max_iterations):\n",
    "        prev_centroids = centroids.copy()\n",
    "        clusters = assign_to_nearest(X, centroids)\n",
    "        centroids = update_centroids(X, clusters, k)\n",
    "        if np.all(prev_centroids == centroids):\n",
    "            break\n",
    "    return clusters, centroids\n",
    "\n",
    "# Application de l'algorithme de k-moyennes à l'ensemble de données Iris\n",
    "k_values = range(1, 20)\n",
    "wcss_values = []\n",
    "\n",
    "new_df.reset_index(drop=True, inplace=True)  # Réinitialiser complètement l'index\n",
    "\n",
    "# Réinitialiser les données après l'opération précédente\n",
    "X_music = new_df.values\n",
    "\n",
    "# Utiliser les données réinitialisées pour l'algorithme de K-moyennes\n",
    "k_values = range(1, 20)\n",
    "wcss_values = []\n",
    "\n",
    "for k in k_values:\n",
    "    clusters, centroids = k_means(X_music, k)\n",
    "    wcss = np.sum((X_music - centroids[clusters.astype(int)]) ** 2)\n",
    "    wcss_values.append(wcss)\n",
    "    \n",
    "# Affichage du graphique pour la méthode du coude\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(k_values, wcss_values, marker='o', linestyle='-')\n",
    "plt.xlabel('Nombre de clusters')\n",
    "plt.ylabel('Somme des carrés des distances intra-cluster')\n",
    "plt.title('Méthode du coude pour déterminer le nombre optimal de clusters')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Méthodes d'évaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(Class_true, Class_pred):\n",
    "    acc = accuracy(Class_true, Class_pred)\n",
    "    prec = precision(Class_true, Class_pred)\n",
    "    rap = rappel(Class_true, Class_pred)\n",
    "    return acc, prec, rap\n",
    "\n",
    "def accuracy(Class_true, Class_pred):\n",
    "    correct = sum(1 for true, pred in zip(Class_true, Class_pred) if true == pred)\n",
    "    total = len(Class_pred)\n",
    "    return \"accuracy =  \" + str(correct / total * 100) + \"%\"\n",
    "\n",
    "def precision(Class_true, Class_pred):\n",
    "    unique_values = np.unique(Class_true)\n",
    "    n = 0\n",
    "    for value in unique_values:\n",
    "        correct = sum(1 for true, pred in zip(Class_true, Class_pred) if true == pred == value)\n",
    "        total = sum(1 for pred in Class_pred if pred == value)\n",
    "        if total != 0 :\n",
    "            n += correct / total\n",
    "    return \"précision =  \" + str(n / len(unique_values) * 100) + \"%\"\n",
    "\n",
    "def rappel(Class_true, Class_pred):\n",
    "    unique_values = np.unique(Class_true)\n",
    "    n = 0\n",
    "    for value in unique_values:\n",
    "        correct = sum(1 for true, pred in zip(Class_true, Class_pred) if true == pred == value)\n",
    "        total = sum(1 for true in Class_true if true == value)\n",
    "        if total != 0 :\n",
    "            n += correct / total\n",
    "    return \"rappel =  \" + str(n / len(unique_values) * 100) + \"%\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stats(test):\n",
    "     \n",
    "     print(metrics.classification_report(test.target, \n",
    "                                         test.hyp, \n",
    "                                         target_names=test.target_name.unique(), \n",
    "                                         zero_division=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('accuracy =  54.947916666666664%',\n",
       " 'précision =  9.15798611111111%',\n",
       " 'rappel =  16.666666666666664%')"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn_zeror(x_train, y_train)\n",
    "\n",
    "pred2 = class_zeror(learn_zeror(x_train, y_train), x_test)\n",
    "\n",
    "evaluate(y_test, pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
